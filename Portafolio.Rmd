---
title: "Portafolio de trabajos Estadistica 1271"
author: "Josue Chango"
date: "2024-11-26"
output: html_document
---

```{css style settings, echo = FALSE}
blockquote {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 14px;
    border-left: 5px solid #eee;
}
``

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


<div style="text-align: center; font-size: 24px; line-height: 1.6;">
# TEMARIO DE CLASES
</div>

## Introducción a la Estadística: Conceptos fundamentales

La estadística es una rama de las matemáticas que se encarga de recolectar, analizar, interpretar y presentar datos. Los conceptos fundamentales incluyen población, muestra, variable, parámetros y estadísticos

## Medidas de tendencia central y dispersion

### Promedio Muestral

El promedio aritmético o muestral, es la medida de tendencia central más comúnmente utilizada, la cual se define de la siguiente manera:

> Sea $x_1, x_2,\ldots, x_n$ un conjunto de $n$ datos muestrales, entonces, el promedio muestral $\bar{X}$ se obtiene de la siguiente manera: $$\bar{X} = \frac{x_1 + x_2 + \ldots x_n}{n} = \frac{\sum_{i=1}^{n}x_i }{n}$$

#### Ejemplo:

Los pesos (en kilogramos) de un grupo de cinco atletas son los siguientes

```{r}

nombres <- c("Atleta 1", "Atleta 2", "Atleta 3", "Atleta 4", "Atleta 5")
pesos <- c(70, 85, 78, 92, 68)

tabla <- as.data.frame(cbind(nombres, pesos))

knitr::kable(t(tabla))

```

El promedio muestral del peso (en kilogramos) de este grupo de atletas se calcularía de la siguiente manera:

$$\bar{X} = \frac{70 + 85 + 78 + 92 + 68}{5} = \frac{393}{5} = 78.6$$
Este promedio se puede calcular paso a paso usando **R** de la siguiente manera:

```{r}

promedio <- (70 + 85 + 78 + 92 + 68)/5
promedio

```

También es posible calcularlo, utilizando la función ***mean***:

```{r}

pesos <- c(70, 85, 78, 92, 68)
promedio <- mean(pesos)
promedio

```

La interpretación geométrica del promedio muestral es similar al concepto del centro de gravedad del conjunto de datos: si distribuimos los puntos observados a lo largo del eje horizontal, entonces el promedio muestral se ubica en el punto en el cual se equilibra el "peso" del conjunto de puntos.

```{r}

stripchart(pesos, method = "stack", pch=16, col = "blue")
abline(v=78.6, col = 2, lwd = 2)
abline(h=0.9, col = 1, lwd = 1)
text(78.6, 0.8, labels = expression(bar(x)))

```

## Medidas de posicion y forma
## Medidas de posicion y forma

### Mediana

La mediana es el valor que divide un conjunto de datos ordenados en dos partes iguales.

#### Ejemplo:

```{r}

valores <- c(7, 3, 5, 9, 6)
mediana <- median(valores)
mediana

```

### Rango Intercuartil (IQR)

El rango intercuartil es una medida de dispersión que describe el intervalo entre el primer cuartil (Q1) y el tercer cuartil (Q3).

#### Ejemplo:

```{r}

valores <- c(7, 3, 5, 9, 6)
IQR(valores)

```

## Probabilidades: Definiciones y técnicas de conteo

La probabilidad de un evento es un número entre 0 y 1 que indica la posibilidad de que el evento ocurra. La probabilidad se define como:

$$P(A) = \frac{\text{Número de casos favorables}}{\text{Número de casos posibles}}
 $$

### Técnica de Conteo: Permutaciones
 
 Las permutaciones se utilizan cuando se desea contar el número de formas en que se pueden ordenar 
***n*** elementos.


#### Ejemplo:


Calcular el número de formas en que se pueden ordenar 4 elementos.

```{r}

factorial(4)

```

## Regla de la adición

La probabilidad de la unión de dos eventos A y B es:

$$P(A \cup B) = P(A) + P(B) - P(A \cap B)
 $$

#### Ejemplo:

$$\text{Si } \ P(A) = 0.3 \text{ y}  \ P(B) = 0.4 \text{ y la probabilidad de que ambos eventos ocurran es } \ P(A \cap B) = 0.1, \text{ entonces: }
 $$
 
 
```{r}

PA <- 0.3
PB <- 0.4
PAB <- 0.1
P_union <- PA + PB - PAB
P_union

```

## Probabilidad Condicional

La probabilidad de A dado B es:

$$P(A \mid B) = \frac{P(A \cap B)}{P(B)}$$

#### Ejemplo

$$\text{Si } P(A \cap B) = 0.1 \text{ y } P(B) = 0.4, \text{ entonces: } $$

```{r}

PAB <- 0.1
PB <- 0.4
P_condicional <- PAB / PB
P_condicional

```

## Regla del producto

La probabilidad de la intersección de dos eventos A y B es:

$$P(A \cap B) = P(A) \cdot P(B \mid A)
$$

#### Ejemplo:

$$\text{Si }P(A) = 0.3 \text{ y } P(B \mid A) = 0.2, \text{ entonces:}
$$
```{r}

PA <- 0.3
PB_A <- 0.2
P_interseccion <- PA * PB_A
P_interseccion

```

## Tablas de contingencia, Arboles de probabilidad

Una tabla de contingencia es una herramienta para resumir la relación entre varias variables categóricas.

#### Ejemplo:

```{r}

tabla <- matrix(c(20, 30, 50, 80), nrow = 2, byrow = TRUE)
colnames(tabla) <- c("Categoria 1", "Categoria 2")
rownames(tabla) <- c("Grupo A", "Grupo B")
tabla <- as.table(tabla)
tabla

```

## Regla de probabilidad Total

La probabilidad total de un evento es la suma de las probabilidades de los eventos que componen el evento total.

#### Ejemplo:

> Sea $A_1, A_2,\ldots, A_n$ son eventos disjuntos, entonces: $$P(B) = \sum_{i=1}^{n} P(B \mid A_i) P(A_i)
$$

```{r}

PA1 <- 0.2
PA2 <- 0.3
PB_A1 <- 0.5
PB_A2 <- 0.4
P_total <- PB_A1 * PA1 + PB_A2 * PA2
P_total

```

## Teorema de Bayes

El teorema de Bayes relaciona la probabilidad condicional y las probabilidades marginales de eventos aleatorios:

$$P(A \mid B) = \frac{P(B\mid A)P(A)}{P(B)}
$$

```{r}

PA <- 0.3
PB_A <- 0.2
PB <- 0.4
P_Bayes <- (PB_A * PA) / PB
P_Bayes

```

## Variables aleatorias discretas y continuas

### Distribución Binomial

La distribución binomial describe el número de éxitos en una secuencia de 
***n*** ensayos de Bernoulli.

#### Ejemplo:

Si lanzamos una moneda 10 veces, ¿cuál es la probabilidad de obtener exactamente 6 caras?

```{r}

n <- 10
p <- 0.5
x <- 6
prob_binomial <- choose(n, x) * p^x * (1-p)^(n-x)
prob_binomial

```

## Distribucion Uniforme

La distribución uniforme continua se define por dos parámetros 
**A** y **B**, que representan los límites inferior y superior del intervalo.

#### Ejemplo:

Si una variable aleatoria tiene una distribución uniforme entre 7 y 10, ¿cuál es la probabilidad de que tome un valor menor a 8.5?

```{r}

A <- 7
B <- 10
P_uniforme <- (8.5 - A) / (B - A)
P_uniforme

```

## Distribucion Normal

La distribución normal es una distribución de probabilidad continua simétrica que se describe con dos parámetros: la media ***μ*** y la desviación estándar ***σ***.

#### Ejemplo:

Si una variable aleatoria sigue una distribución normal con media **μ=0** y desviación estándar **σ=1**, ¿cuál es la probabilidad de que la variable tome un valor menor a 1.96?

```{r}

mu <- 0
sigma <- 1
x <- 1.96
p <- pnorm(x, mean = mu, sd = sigma)
p

```

### Grafico de la distribucion normal:

```{r}

curve(dnorm(x, mean = mu, sd = sigma), from = -4, to = 4, main = "Distribución Normal Estándar", ylab = "Densidad")
abline(v = x, col = "red")

```

## Esperanza Matematica

La esperanza matemática (o valor esperado) de una variable aleatoria 
*X* es el promedio ponderado de todos los valores posibles que *X* puede tomar.

$$E(X) = \sum_{i=1}^{n} x_i P(x_i)
$$

#### Ejemplo:

Si una variable aleatoria discreta *X* toma los valores 1, 2, y 3 con probabilidades 0.2, 0.5, y 0.3 respectivamente, la esperanza matemática es:

#### Manual:

$$E(X) = 1 \cdot 0.2 + 2 \cdot 0.5 + 3 \cdot 0.3 = 2.1
$$

#### En ***R***

```{r}

valores <- c(1, 2, 3)
probabilidades <- c(0.2, 0.5, 0.3)
esperanza <- sum(valores * probabilidades)
esperanza

```

## Varianza

La varianza de una variable aleatoria *X* es la esperanza del cuadrado de su desviación respecto a su media.

$$\text{Var}(X) = E[(X - E(X))^2]
$$

#### Ejemplo:

Usando los valores y probabilidades del ejemplo anterior:

#### Manual:

$$\text{Var}(X) = (1 - 2.1)^2 \cdot 0.2 + (2 - 2.1)^2 \cdot 0.5 + (3 - 2.1)^2 \cdot 0.3 = 0.49
$$

#### En ***R***

```{r}

esperanza <- 2.1
varianza <- sum((valores - esperanza)^2 * probabilidades)
varianza

```

## Distribuciones Discretas: Bernoulli

La distribución Bernoulli describe un experimento binario (éxito o fracaso) con probabilidad de éxito 
*p*.

#### Ejemplo:

Simularemos datos de una variable que sigue una distribución de Bernoulli. Supongamos que realizamos 150 experimentos donde la probabilidad de éxito es 0.6. Queremos calcular la media de los resultados y visualizar la frecuencia de éxitos y fracasos.

```{r}

# Simulación de datos de una distribución de Bernoulli
set.seed(123)  # Establecemos una semilla para reproducibilidad
n <- 150        # Número de experimentos
p <- 0.6        # Probabilidad de éxito

# Generar los datos
datos_bernoulli <- rbinom(n, 1, p)

# Calcular la media de los datos
media <- mean(datos_bernoulli)
cat("La media de la distribución de Bernoulli es:", media, "\n")

# Crear un gráfico de barras
barplot(table(datos_bernoulli), col = c("red", "blue"), 
        names.arg = c("Fracaso (0)", "Éxito (1)"),
        main = "Frecuencia de Éxitos y Fracasos",
        ylab = "Frecuencia")

```

## Distribucion Binomial

La distribución binomial describe el número de éxitos en *n* ensayos de Bernoulli.

#### Ejemplo:

En este ejemplo, simularemos datos de una variable que sigue una distribución binomial. Supongamos que realizamos 200 ensayos donde la probabilidad de éxito en cada ensayo es 0.3. Queremos calcular la media, la varianza y visualizar la distribución de los resultados.

```{r}
# Simulación de datos de una distribución binomial
set.seed(456)  # Establecemos una semilla para reproducibilidad
n <- 200        # Número total de ensayos
p <- 0.3        # Probabilidad de éxito en cada ensayo

# Generar los datos
datos_binomial <- rbinom(n, size = 1, prob = p)

# Calcular la media y la varianza de los datos
media <- mean(datos_binomial)
varianza <- var(datos_binomial)
cat("La media de la distribución binomial es:", media, "\n")
cat("La varianza de la distribución binomial es:", varianza, "\n")

# Crear un histograma de los datos
hist(datos_binomial, breaks = 20, col = "skyblue",
     main = "Distribución Binomial",
     xlab = "Número de Éxitos",
     ylab = "Frecuencia")

```
## Distribucion de Poisson

La distribución de Poisson describe el número de eventos en un intervalo fijo de tiempo o espacio.

#### Ejemplo:

Si el número de llamadas por hora es una variable aleatoria de Poisson con λ=6, ¿cuál es la probabilidad de recibir exactamente 4 llamadas en una hora?

#### Manual:

Usando la fórmula de la distribución de Poisson:

$$P(X=4) = \frac{\lambda^4 e^{-\lambda}}{4!} = 0.1339
$$

#### En ***R***:

```{r}

#Usando la formula directa

lambda = 6

p4 = exp(-lambda)*lambda^4 / factorial(4)
p4

#Usando la funcion 'dpois()' en R

lambda = 6
x = 4
prob_poisson = dpois(x, lambda)
prob_poisson

```

## Aplicaciones de la Distribución Normal: Aproximación a la Binomial

>Cuando \( n \) es grande, la distribución binomial \( B(n,p) \) se puede aproximar con una distribución normal \( N(np, \sqrt{np(1-p)}) \).

#### Ejemplo:

Para n = 100 y p = 0.5, calcular la probabilidad de obtener entre 45 y 55 éxitos.

#### Manual:

Aproximacion usando la normal:

$$\mu = np = 100 \cdot 0.5 = 50
$$
$$\sigma = \sqrt{np(1-p)} = \sqrt{100 \cdot 0.5 \cdot 0.5} = 5
$$

#### En ***R***:

```{r}

n <- 100
p <- 0.5
mu <- n * p
sigma <- sqrt(n * p * (1 - p))
prob <- pnorm(55, mean = mu, sd = sigma) - pnorm(45, mean = mu, sd = sigma)
prob

```

<div style="text-align: center; font-size: 24px; line-height: 1.6;">
# RESOLUCION DE EJERCICIOS PROPUESTOS
</div>


<div style="text-align: center; font-size: 14px; line-height: 1.6;">
# Ejercicios de resolucion manual
</div>

## 1

Los datos siguientes representan los pesos de los recien nacidos en un hospital de una gran ciudad del este de Estados  Unidos.
  
  
```{r}

Pesos = c(2.4, 3.3, 4.1,5.0,5.1,5.2,5.6,5.8,5.9,5.9,6.0,6.1,6.2,6.3,6.3,6.4,6.4,6.5,6.7,6.8,7.2,7.4,7.5,7.5,7.6,7.6,7.7,7.8,7.8,7.9,7.9,8.3,8.5,8.8,9.2,9.7,9.8,9.9,10.0,10.3,10.5)

```
### (A) Represéntelos gráficamente mediante un diagrama de tallos y hojas.

```{r}
library(ggplot2)
datos <- c(2.4, 3.3, 4.1, 5.0, 5.1, 5.2, 5.6, 5.8, 5.9, 5.9, 6.0, 6.1, 6.2, 6.3, 
          6.3, 6.4, 6.4, 6.5, 6.7, 6.8, 7.2, 7.4, 7.5, 7.5, 7.6, 7.6, 7.7, 7.8,
          7.8, 7.9, 7.9, 8.3, 8.5, 8.8, 9.2, 9.7, 9.8, 9.9, 10.0, 10.3, 10.5)
ggplot(data.frame(value = datos), aes(value)) + 
  geom_histogram(binwidth = 0.5, fill = "steelblue", color = "black") +
  labs(title = "Diagrama de tallos y hojas", x = "Peso", y = "Frecuencia")
```

### (B) Encuentre la media muestral $\hat{x}$.


La media muestral se calcula sumando todos los valores y dividiendo entre el número total de datos:

$\bar{x} = \frac{\sum_{i=1}^{n} x_i}{n}$

$\sum_{i=1}^{n} x_i = 2.4+3.3+4.1+5.0+5.1+5.2+5.6+5.8+5.9+5.9+6.0+6.1+6.2+$
$6.3+6.3+6.4+6.4+6.5+6.7+6.8+7.2+7.4+7.5+7.5+7.6+7.6+7.7+7.8+$
$7.8+7.9+7.9+8.3+8.5+8.8+9.2+9.7+9.8+9.9+10.0+10.3+10.5 = 244.6$

Número total de datos $n = 40$

$\hat{x} = \frac{244.6}{40} = 6.115$

### (C) Encontrar la mediana muestral

Para calcular la mediana, primero ordenamos los datos de menor a mayor:

2.4, 3.3, 4.1, 5.0, 5.1, 5.2, 5.6, 5.8, 5.9, 5.9, 6.0, 6.1, 6.2, 6.3, 6.3, 6.4, 6.4, 6.5, 6.7, 6.8, 7.2, 7.4, 7.5, 7.5, 7.6, 7.6, 7.7, 7.8, 7.8, 7.9, 7.9, 8.3, 8.5, 8.8, 9.2, 9.7, 9.8, 9.9, 10.0, 10.3, 10.5

Como el número de datos es par (40), la mediana es el promedio de los dos valores centrales:

$Mediana = \frac{6.4 + 6.5}{2} = 6.45$

### (D) Calcular la desviación típica muestral $s$

$\sqrt{\frac{\sum_{i=1}^{n} (x_i-\hat{x})^2 }{n-1}}$

Donde $\bar{x}$ es la media muestral calculada anteriormente.

Desarrollando el cálculo:

\[s = \sqrt{\frac{(2.4 - 6.115)^2 + (3.3 - 6.115)^2 + \ldots + (10.5 - 6.115)^2}{40 - 1}}\]

\[s = \sqrt{\frac{13.7225 + 8.8225 + \ldots + 16.3225}{39}}\]

\[s = \sqrt{\frac{1311.1}{39}}\]

\[s = \sqrt{33.6}\]

\[s = 5.8\]
